# üß† Knowledge Graph RAG with Neo4j + LangChain

This repository demonstrates how to build a **Knowledge Graph** for use in **Graph RAG** (Retrieval-Augmented Generation) using [Neo4j](https://neo4j.com/) and [LangChain](https://www.langchain.com/). It includes both a Jupyter notebook for Knowledge Graph construction and a **GraphRAG MCP Server** that can be deployed with Docker and integrated with tools like n8n.

---

## üéØ Features

- **Knowledge Graph RAG**: Build and query knowledge graphs using Neo4j
- **MCP Server**: Model Context Protocol server for integration with n8n and other tools
- **Docker Support**: Containerized deployment with Docker Compose
- **Neo4j AuraDB Support**: Connect to cloud-hosted Neo4j instances
- **Hybrid Search**: Combines graph traversal and vector similarity search

---

## üìã Requirements

Before getting started, make sure the following tools are installed on your machine:

### üõ†Ô∏è Tools

* **Python 3.8+**
  [https://www.python.org/downloads/](https://www.python.org/downloads/)

* **Docker Desktop**
  [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)


---

## üöÄ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/Kanisorn-S/agentic-graphrag-langchain.git
cd agentic-graphrag-langchain
```

---

### 2. Set Up Environment Variables

Copy the `.env.example` file and populate with your credentials:

```bash
cp .env.example .env
```

Then edit `.env`:

```env
# .env
GEMINI_API_KEY=your-gemini-api-key
NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-auradb-password
LLM_TYPE=ollama  # or 'google' for Gemini
OLLAMA_MODEL=llama3.1
```

---

### 3. Choose Your Deployment Method

#### Option A: Docker Deployment (Recommended)

**For GraphRAG MCP Server with AuraDB:**
```bash
# Start the GraphRAG MCP Server (connects to your AuraDB)
docker-compose up --build 
```

The services will be available at:
- **GraphRAG MCP Server**: [http://localhost:8000](http://localhost:8000)
- **Neo4j Browser** (if running locally): [http://localhost:7474](http://localhost:7474)

#### Option B: Local Python Development

1. **Set Up a Python Virtual Environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate       # Mac/Linux
   venv\Scripts\activate          # Windows
   ```

2. **Install Dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the Server:**
   ```bash
   python graphrag_mcp_server.py
   ```

---

### 4. Using the GraphRAG MCP Server

#### Available Endpoints:

- **`GET /query`**: Query the knowledge graph with natural language
- **`GET /entities`**: Extract entities from text
- **`GET /graph_search`**: Search for entity relationships
- **`GET /vector_search`**: Perform vector similarity search
- **`GET /health`**: Health check

#### Example API Calls:

```bash
# Query the knowledge graph
curl "http://localhost:8000/query?query=‡∏Å‡∏≤‡∏£‡∏à‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏µ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®"

# Extract entities
curl "http://localhost:8000/entities?text=‡∏†‡∏≤‡∏©‡∏µ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏ä‡∏≠‡∏≤‡∏ì‡∏≤‡∏à‡∏±‡∏Å‡∏£"

# Search graph relationships
curl "http://localhost:8000/graph_search?entity=‡∏£‡∏≤‡∏ä‡∏≠‡∏≤‡∏ì‡∏≤‡∏à‡∏±‡∏Å‡∏£"
```

---

### 5. Integration with n8n

The GraphRAG MCP Server implements the Model Context Protocol and can be integrated with n8n:

**n8n MCP Configuration:**
- **Command**: `python`
- **Arguments**: `["path/to/graphrag_mcp_server.py"]`
- **Environment Variables**: Your `.env` variables

See `n8n_configuration.md` for detailed setup instructions.

---

### 6. Jupyter Notebook Development


Open the notebook file (`graphrag.ipynb`) and execute the cells step by step to build and query your knowledge graph. Make sure the notebook is using the virtual environment you've just created.

---

### 7. Stop Services 

When you are done, run

```bash
docker-compose down
```

This will stop all running services.

---

## üê≥ Docker Services

The `docker-compose.yml` file includes:

- **stirling-pdf**: PDF processing tools (port 8080)
- **graphrag-mcp**: GraphRAG MCP Server (port 8000)

### Environment Variables

All Neo4j and LLM configurations are loaded from your `.env` file:

- `NEO4J_URI` - Neo4j connection URI (local or AuraDB)
- `NEO4J_USERNAME` - Neo4j username
- `NEO4J_PASSWORD` - Neo4j password
- `LLM_TYPE` - LLM provider (`ollama` or `google`)
- `OLLAMA_MODEL` - Ollama model name
- `GEMINI_API_KEY` - Google Gemini API key

---

## üîß Model Context Protocol (MCP)

The server implements MCP specification for integration with AI tools:

**Available Tools:**
1. **graphrag_query** - Query the knowledge graph
2. **extract_entities** - Extract entities from text
3. **search_graph** - Search graph relationships

**Usage with MCP Clients:**
```json
{
  "tool": "graphrag_query",
  "arguments": {
    "query": "your question here"
  }
}
```

## üß± Folder Structure

```
agentic-graphrag-langchain/
‚îú‚îÄ‚îÄ docs/                    # Document files for knowledge graph
‚îÇ   ‚îú‚îÄ‚îÄ 83_84.txt
‚îÇ   ‚îú‚îÄ‚îÄ revenue_dep.txt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ n8n/                      # n8n workflows
‚îÇ   ‚îú‚îÄ‚îÄ subworkflow/          # Sub-agents and tools
|   ‚îÇ   ‚îú‚îÄ‚îÄ Google_Search_and_Scrape.json  # Tools for searching Google
|   ‚îÇ   |‚îÄ‚îÄ Retriever_Agent_HTTP.json           # Retriver Agent with access to Hybrid Search
|   ‚îÇ   ‚îî‚îÄ‚îÄ Retriever_Agent_MCP.json            # Retriver Agent with access to Vector Search and Graph Search tools
‚îÇ   ‚îî‚îÄ‚îÄ workflow/
|       |‚îÄ‚îÄ Document_Parsing_MultiModal_Graph_API.json   # Main Workflow for Document Insertion and GraphRAG Using HTTP Retriever
|       ‚îî‚îÄ‚îÄ Document_Parsing_MultiModal_Graph_MCP.json   # Main Workflow for Document Insertion and GraphRAG Using MCP Retriever
‚îú‚îÄ‚îÄ .env.example             # Template env file
‚îú‚îÄ‚îÄ .env                     # Your environment variables
‚îú‚îÄ‚îÄ docker-compose.yml       # Docker services definition
‚îú‚îÄ‚îÄ Dockerfile               # GraphRAG MCP Server container
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îú‚îÄ‚îÄ graphrag_mcp_server.py   # GraphRAG MCP Server (FastAPI + MCP)
‚îú‚îÄ‚îÄ graphrag.ipynb          # Jupyter notebook for exploration
‚îú‚îÄ‚îÄ n8n_configuration.md    # n8n integration guide
‚îî‚îÄ‚îÄ README.md               # This file
```
